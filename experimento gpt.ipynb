{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos y analisis de gpt3-5 y gpt4 para incorporar a la automatizacion de tareas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de IA Generativa para incorporar a Klearty\n",
    "\n",
    "En este análisis, se exploran pruebas con distintos *prompts* y conjuntos de datos. Hasta ahora, se han diseñado tres funciones principales:\n",
    "\n",
    "1. **Clusterización de Variables Categóricas**: Agrupa variables categóricas para simplificar los modelos y mejorar su interpretabilidad.\n",
    "2. **Selección de Variables**: Identifica las variables menos relevantes para los modelos, ayudando a reducir la dimensión del conjunto de datos.\n",
    "3. **Explicación del Modelo**: Proporciona insights sobre cómo el modelo toma decisiones, lo cual es crucial para la interpretación de los resultados.\n",
    "\n",
    "Se espera expandir estas funcionalidades para analizar más aspectos de los datos, como la informacion del EDA , y el modelo para entender mejor las métricas de los modelos. Esto permitirá ofrecer explicaciones o sugerencias de mayor calidad. Además, se considera la posibilidad de incorporar análisis para mejorar la detección de anomalías, generar más datos y, en caso de contar con reseñas o quejas, extraer información procesable para los modelos de Machine Learning.\n",
    "\n",
    "Este análisis demuestra el potencial de estas herramientas para automatizar tareas que tradicionalmente requerían un proceso manual por parte de los científicos de datos. Se destaca un interesante salto de calidad entre las versiones GPT-3 y GPT-4, así como también en la diferencia de precio entre ambas.\n",
    "\n",
    "Un punto a considerar es que la respuesta de la API puede superar los 30 segundos, y es habitual encontrar momentos en los que no funciona adecuadamente.\n",
    "\n",
    "Por estas razones, se sugiere que estos modelos de IA Generativa se vean como un version de mayor calidad en nuestros procesos actuales. El objetivo es mejorar la calidad de los datos con los que entrenamos los modelos, lo cual, a su vez, debería reflejarse en una mejora de las métricas de los mismos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parametros import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumimos que nos da un archivos y un nombre de archivo ( Caso solo csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name,file_path):\n",
    "    \n",
    "    if file_name.split('.')[-1]=='csv':\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"el archivo se pudo leer con exito\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"la extencion del archivo no es valida\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el archivo se pudo leer con exito\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.11</th>\n",
       "      <th>Unnamed: 0.10</th>\n",
       "      <th>Unnamed: 0.9</th>\n",
       "      <th>Unnamed: 0.8</th>\n",
       "      <th>Unnamed: 0.7</th>\n",
       "      <th>Unnamed: 0.6</th>\n",
       "      <th>Unnamed: 0.5</th>\n",
       "      <th>Unnamed: 0.4</th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.11  Unnamed: 0.10  Unnamed: 0.9  Unnamed: 0.8  Unnamed: 0.7  \\\n",
       "0              0              0             0             0             0   \n",
       "1              1              1             1             1             1   \n",
       "2              2              2             2             2             2   \n",
       "\n",
       "   Unnamed: 0.6  Unnamed: 0.5  Unnamed: 0.4  Unnamed: 0.3  Unnamed: 0.2  ...  \\\n",
       "0             0             0             0             0             0  ...   \n",
       "1             1             1             1             1             1  ...   \n",
       "2             2             2             2             2             2  ...   \n",
       "\n",
       "   DeviceProtection  TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0                No           No          No              No  Month-to-month   \n",
       "1               Yes           No          No              No        One year   \n",
       "2                No           No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling     PaymentMethod  MonthlyCharges TotalCharges Churn  \n",
       "0              Yes  Electronic check           29.85        29.85    No  \n",
       "1               No      Mailed check           56.95       1889.5    No  \n",
       "2              Yes      Mailed check           53.85       108.15   Yes  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "file_path = \"datos_input/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "df = read_file(file_name,file_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_target(df,target):\n",
    "    df.rename(columns = {target:'y'}, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos Informacion basica del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del archivo: WA_Fn-UseC_-Telco-Customer-Churn\n",
      "Cantidad de filas: 7043 \n",
      "Cantidad de columnas: 33\n",
      "Nombres de columnas: ['Unnamed: 0.11', 'Unnamed: 0.10', 'Unnamed: 0.9', 'Unnamed: 0.8', 'Unnamed: 0.7', 'Unnamed: 0.6', 'Unnamed: 0.5', 'Unnamed: 0.4', 'Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
      "Cantidad de valores nulos 0\n",
      "Porcentaje de valores nulos 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre del archivo:\",file_name.split('.')[0])\n",
    "\n",
    "shape = df.shape\n",
    "print(\"Cantidad de filas:\",shape[0],\"\\nCantidad de columnas:\",shape[1])\n",
    "\n",
    "print(\"Nombres de columnas:\", list(df.columns))\n",
    "\n",
    "total_null_value = df.isnull().sum().sum()\n",
    "pct_null_value = total_null_value / (shape[0]*shape[1])\n",
    "print(\"Cantidad de valores nulos\",total_null_value)\n",
    "print(\"Porcentaje de valores nulos\",pct_null_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN AI - Prompt Engeniering para el analisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Obtaining dependency information for openai==0.28 from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from openai==0.28) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from openai==0.28) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ferre\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/76.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.5/76.5 kB 850.1 kB/s eta 0:00:00\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.12.0\n",
      "    Uninstalling openai-1.12.0:\n",
      "      Successfully uninstalled openai-1.12.0\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos una funcion que determine  categorias mas generarales para las variables categoricas de mas de 6 elementos. Esto va a servir para la parte de la limpieza de datos. EJ Bs AS y buenos aires . Y  por otro lado va a hacer una tarea similar a los embedings. Pensemos en un analista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "profesiones_comunes = [\n",
    "    \"Médico\", \"Ingeniero\", \"Profesor\", \"Enfermero/a\", \"Dentista\", \"Psicólogo\", \"Policía\", \"Bombero/a\", \"Chef\", \"Mecánico\",\n",
    "    \"Electricista\", \"Peluquero/a\", \"Actor/Actriz\", \"Cantante\", \"Escritor\", \"Diseñador gráfico\", \"Programador\", \"Periodista\", \"Agricultor\", \"Veterinario\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Categoría 1\": [\"Médico\", \"Enfermero/a\", \"Dentista\", \"Psicólogo\", \"Veterinario\"],\n",
      "  \"Categoría 2\": [\"Ingeniero\", \"Programador\", \"Diseñador gráfico\"],\n",
      "  \"Categoría 3\": [\"Profesor\", \"Periodista\"],\n",
      "  \"Categoría 4\": [\"Policía\", \"Bombero/a\"],\n",
      "  \"Categoría 5\": [\"Chef\"],\n",
      "  \"Categoría 6\": [\"Mecánico\", \"Electricista\"],\n",
      "  \"Categoría 7\": [\"Peluquero/a\"],\n",
      "  \"Categoría 8\": [\"Actor/Actriz\", \"Cantante\", \"Escritor\"],\n",
      "  \"Categoría 9\": [\"Agricultor\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key  = \"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\"\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "prompt = f\"\"\"Agrupa los objetos en categorías basadas en su similitud, sin límite predefinido en el número de categorías. Asegúrate de que los objetos dentro de cada categoría sean similares. Genera el resultado en formato JSON donde para cada categoría aparezca un nombre representativo y como valor una lista de los objetos que están dentro de esa categoría. Cada categoría debe tener un nombre que refleje lo que representa. Lista de objetos: {profesiones_comunes}\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Agrupa los objetos en categorías basadas en su similitud, sin límite predefinido en el número de categorías. Asegúrate de que los objetos dentro de cada categoría sean similares. Genera el resultado en formato JSON donde para cada categoría aparezca un nombre representativo y como valor una lista de los objetos que están dentro de esa categoría. Cada categoría debe tener un nombre que refleje lo que representa. Lista de objetos: {profesiones_comunes}\"\"\"\n",
    "response = str(categorias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimar_tokens(prompt):\n",
    "    # Tokenización simple basada en espacios y signos de puntuación comunes\n",
    "    palabras = prompt.replace('\\n', ' ').replace('.', ' ').replace(',', ' ').replace('?', ' ').replace('!', ' ').split()\n",
    "    num_tokens = len(palabras)  # Cada palabra se considera un token\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_tokens 91\n",
      "output_tokens 39\n",
      "costo en dolares:  0.00051 costo en pesos:  0.663\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = estimar_tokens(prompt)\n",
    "print(\"prompt_tokens\",prompt_tokens)\n",
    "output_tokens = estimar_tokens(response)\n",
    "print(\"output_tokens\",output_tokens)\n",
    "\n",
    "costo = round(calcular_costo(prompt_tokens,output_tokens),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo en dolares:  0.00051 costo en pesos:  0.663\n"
     ]
    }
   ],
   "source": [
    "def calcular_costo(input_tokens, output_tokens):\n",
    "    costo_por_input = 0.0030  # Costo por cada 1K tokens de entrada\n",
    "    costo_por_output = 0.0060  # Costo por cada 1K tokens de salida\n",
    "\n",
    "    costo_total = (input_tokens * costo_por_input / 1000) + (output_tokens * costo_por_output / 1000)\n",
    "    \n",
    "    return costo_total\n",
    "\n",
    "costo = round(calcular_costo(91,39),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego mensaje al dicc que indica como hizo la separacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Profesiones de la salud\": [\"Médico\", \"Enfermero/a\", \"Dentista\", \"Psicólogo\", \"Veterinario\"],\n",
      "  \"Profesiones técnicas\": [\"Ingeniero\", \"Mecánico\", \"Electricista\", \"Diseñador gráfico\", \"Programador\"],\n",
      "  \"Profesiones educativas\": [\"Profesor\"],\n",
      "  \"Profesiones de servicio y protección\": [\"Policía\", \"Bombero/a\"],\n",
      "  \"Profesiones artísticas\": [\"Actor/Actriz\", \"Cantante\", \"Escritor\"],\n",
      "  \"Profesiones relacionadas con la alimentación\": [\"Chef\"],\n",
      "  \"Profesiones relacionadas con la estética\": [\"Peluquero/a\"],\n",
      "  \"Profesiones relacionadas con los medios de comunicación\": [\"Periodista\"],\n",
      "  \"Profesiones relacionadas con la agricultura\": [\"Agricultor\"]\n",
      "}\n",
      "\n",
      "Criterio utilizado para la clasificación: Se agruparon los objetos según su campo de trabajo o área de especialización.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Clasifica la siguiente lista de objetos en categorías según sus similitudes, sin un límite específico de categorías.\n",
    "Garantiza la homogeneidad dentro de cada categoría.\n",
    "El resultado debe presentarse en un formato JSON,\n",
    "donde cada categoría esté identificada por un nombre descriptivo y contenga una lista de los objetos pertenecientes.\n",
    "El nombre de cada categoría debe reflejar claramente las características comunes de sus miembros.\n",
    "Incluye además un mensaje breve que explique el criterio utilizado para la clasificación,\n",
    " limitado a una oración. Lista de objetos:{profesiones_comunes}\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_tokens 103\n",
      "output_tokens 78\n",
      "costo en dolares:  0.00078 costo en pesos:  1.014\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = estimar_tokens(prompt)\n",
    "print(\"prompt_tokens\",prompt_tokens)\n",
    "output_tokens = estimar_tokens(response)\n",
    "print(\"output_tokens\",output_tokens)\n",
    "\n",
    "costo = round(calcular_costo(prompt_tokens,output_tokens),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'Categoría 1': ['Médico', 'Enfermero/a', 'Dentista', 'Psicólogo', 'Veterinario'], 'Categoría 2': ['Ingeniero', 'Programador', 'Diseñador gráfico'], 'Categoría 3': ['Profesor', 'Periodista'], 'Categoría 4': ['Policía', 'Bombero/a'], 'Categoría 5': ['Chef'], 'Categoría 6': ['Mecánico', 'Electricista'], 'Categoría 7': ['Peluquero/a'], 'Categoría 8': ['Actor/Actriz', 'Cantante', 'Escritor'], 'Categoría 9': ['Agricultor']}\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias = {\n",
    "    \"Categoría 1\": [\"Médico\", \"Enfermero/a\", \"Dentista\", \"Psicólogo\", \"Veterinario\"],\n",
    "    \"Categoría 2\": [\"Ingeniero\", \"Programador\", \"Diseñador gráfico\"],\n",
    "    \"Categoría 3\": [\"Profesor\", \"Periodista\"],\n",
    "    \"Categoría 4\": [\"Policía\", \"Bombero/a\"],\n",
    "    \"Categoría 5\": [\"Chef\"],\n",
    "    \"Categoría 6\": [\"Mecánico\", \"Electricista\"],\n",
    "    \"Categoría 7\": [\"Peluquero/a\"],\n",
    "    \"Categoría 8\": [\"Actor/Actriz\", \"Cantante\", \"Escritor\"],\n",
    "    \"Categoría 9\": [\"Agricultor\"]\n",
    "}\n",
    "\n",
    "str( categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Profesiones de la Salud\": [\"Médico\", \"Enfermero/a\", \"Dentista\", \"Psicólogo\", \"Veterinario\"],\n",
      "    \"Profesiones de la Ingeniería y Tecnología\": [\"Ingeniero\", \"Mecánico\", \"Electricista\", \"Programador\"],\n",
      "    \"Profesiones de la Educación\": [\"Profesor\"],\n",
      "    \"Profesiones de la Seguridad\": [\"Policía\", \"Bombero/a\"],\n",
      "    \"Profesiones de la Gastronomía\": [\"Chef\"],\n",
      "    \"Profesiones de la Belleza y Estética\": [\"Peluquero/a\"],\n",
      "    \"Profesiones del Arte y Entretenimiento\": [\"Actor/Actriz\", \"Cantante\", \"Escritor\"],\n",
      "    \"Profesiones del Diseño\": [\"Diseñador gráfico\"],\n",
      "    \"Profesiones de la Comunicación\": [\"Periodista\"],\n",
      "    \"Profesiones de la Agricultura\": [\"Agricultor\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key  = \"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\"\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "prompt = f\"\"\"Agrupa los objetos en categorías basadas en su similitud, sin límite predefinido en el número de categorías. Asegúrate de que los objetos dentro de cada categoría sean similares. Genera el resultado en formato JSON donde para cada categoría aparezca un nombre representativo y como valor una lista de los objetos que están dentro de esa categoría. Cada categoría debe tener un nombre que refleje lo que representa. Lista de objetos: {profesiones_comunes}\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Profesiones de la salud\": [\"Médico\", \"Enfermero/a\", \"Dentista\", \"Psicólogo\", \"Veterinario\"],\n",
      "    \"Profesiones de la educación\": [\"Profesor\"],\n",
      "    \"Profesiones de seguridad y emergencias\": [\"Policía\", \"Bombero/a\"],\n",
      "    \"Profesiones de servicios\": [\"Chef\", \"Peluquero/a\"],\n",
      "    \"Profesiones técnicas y de ingeniería\": [\"Ingeniero\", \"Mecánico\", \"Electricista\", \"Programador\"],\n",
      "    \"Profesiones creativas y de entretenimiento\": [\"Actor/Actriz\", \"Cantante\", \"Escritor\", \"Diseñador gráfico\"],\n",
      "    \"Profesiones de comunicación\": [\"Periodista\"],\n",
      "    \"Profesiones de la agricultura\": [\"Agricultor\"]\n",
      "}\n",
      "\n",
      "Mensaje: Las profesiones se han clasificado en categorías basadas en el campo de trabajo y las habilidades requeridas.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Clasifica la siguiente lista de objetos en categorías según sus similitudes, sin un límite específico de categorías.\n",
    "Garantiza la homogeneidad dentro de cada categoría.\n",
    "El resultado debe presentarse en un formato JSON,\n",
    "donde cada categoría esté identificada por un nombre descriptivo y contenga una lista de los objetos pertenecientes.\n",
    "El nombre de cada categoría debe reflejar claramente las características comunes de sus miembros.\n",
    "Incluye además un mensaje breve que explique el criterio utilizado para la clasificación,\n",
    " limitado a una oración. Lista de objetos:{profesiones_comunes}\"\"\"\n",
    "\n",
    "response2 = get_completion(prompt)\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo en dolares:  0.00507 costo en pesos:  6.591\n"
     ]
    }
   ],
   "source": [
    "def calcular_costo_gpt4(input_tokens, output_tokens):\n",
    "    costo_por_input = 0.03  # Costo por cada 1K tokens de entrada\n",
    "    costo_por_output = 0.06  # Costo por cada 1K tokens de salida\n",
    "\n",
    "    costo_total = (input_tokens * costo_por_input / 1000) + (output_tokens * costo_por_output / 1000)\n",
    "    \n",
    "    return costo_total\n",
    "\n",
    "costo = round(calcular_costo_gpt4(91,39),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_tokens 103\n",
      "output_tokens 74\n",
      "costo en dolares:  0.00753 costo en pesos:  9.789\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = estimar_tokens(prompt)\n",
    "print(\"prompt_tokens\",prompt_tokens)\n",
    "output_tokens = estimar_tokens(response2)\n",
    "print(\"output_tokens\",output_tokens)\n",
    "\n",
    "costo = round(calcular_costo_gpt4(prompt_tokens,output_tokens),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba seleccion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "df_string = new_df.head(2).to_string()\n",
    "df_string\n",
    "print(estimar_tokens(df_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"columnas_a_eliminar\": [\n",
      "    \"Unnamed: 0.11\",\n",
      "    \"Unnamed: 0.10\",\n",
      "    \"Unnamed: 0.9\",\n",
      "    \"Unnamed: 0.8\",\n",
      "    \"Unnamed: 0.7\",\n",
      "    \"Unnamed: 0.6\",\n",
      "    \"Unnamed: 0.5\",\n",
      "    \"Unnamed: 0.4\",\n",
      "    \"Unnamed: 0.3\",\n",
      "    \"Unnamed: 0.2\",\n",
      "    \"Unnamed: 0.1\",\n",
      "    \"Unnamed: 0\",\n",
      "    \"customerID\"\n",
      "  ],\n",
      "  \"razones\": [\n",
      "    \"Las columnas 'Unnamed: 0.x' parecen ser índices redundantes que no aportan información útil para la predicción de la variable objetivo 'y'.\",\n",
      "    \"La columna 'customerID' es un identificador único para cada cliente y no tiene relevancia predictiva para la variable objetivo.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Dado el siguiente DataFrame con una muestra de dos filas y varias columnas,\n",
    "identifica qué columnas podrían ser innecesarias para un análisis en el que la columna 'y'\n",
    "es la variable objetivo.\n",
    "Considera factores como redundancia de datos, relevancia para la predicción de la variable objetivo,\n",
    "y cualquier otro criterio analítico que consideres pertinente. Retorna el resultado en un formato JSON,\n",
    "especificando las columnas a eliminar y proporciona una breve explicación de por qué deberían ser eliminadas.\n",
    "Ejemplo de DataFrame: {df_string}\"\"\"\n",
    "\n",
    "response3 = get_completion(prompt)\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_tokens 213\n",
      "output_tokens 87\n",
      "costo en dolares:  0.01161 costo en pesos:  15.093\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = estimar_tokens(prompt)\n",
    "print(\"prompt_tokens\",prompt_tokens)\n",
    "output_tokens = estimar_tokens(response3)\n",
    "print(\"output_tokens\",output_tokens)\n",
    "\n",
    "costo = round(calcular_costo_gpt4(prompt_tokens,output_tokens),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis final del resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"RandomForest\"\n",
    "Accuracy = \"79\"\n",
    "principal_variables  = str([\"TotalCharges\", \"MonthlyCharges\", \"tenure\", \"Contract\", \"PaymentMethod\", \"OnlineSecurity\", \"TechSupport\", \"gender\", \"PaperlessBilling\", \"InternetService\"])\n",
    "df_string = new_df.head(2).to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Análisis Técnico**:\n",
      "\n",
      "El modelo RandomForest tiene una precisión del 79%, lo que indica que el modelo es capaz de predecir correctamente si un cliente se irá o no en el 79% de los casos. Sin embargo, la precisión por sí sola no es suficiente para evaluar la efectividad del modelo. Sería útil conocer otras métricas como la sensibilidad, la especificidad, el valor predictivo positivo y negativo, y el área bajo la curva ROC.\n",
      "\n",
      "En cuanto a las variables más explicativas, parece haber un error en los datos proporcionados ya que se menciona que son \"79\". Sin embargo, basándonos en el DataFrame proporcionado, algunas variables que podrían ser importantes para predecir el churn podrían ser 'tenure' (tiempo que el cliente ha estado con la empresa), 'Contract' (tipo de contrato del cliente), 'MonthlyCharges' (cargos mensuales) y 'TotalCharges' (cargos totales). Estas variables podrían ser importantes porque los clientes que han estado con la empresa durante más tiempo, tienen contratos a largo plazo y cargos más bajos podrían ser menos propensos a irse.\n",
      "\n",
      "2. **Análisis de Negocio**:\n",
      "\n",
      "Este modelo puede ser muy valioso para la empresa ya que puede ayudar a identificar a los clientes que están en riesgo de irse. Con esta información, la empresa puede tomar medidas para retener a estos clientes, como ofrecer descuentos, mejorar el servicio al cliente o personalizar las ofertas según las necesidades del cliente.\n",
      "\n",
      "Por ejemplo, si el modelo identifica que los clientes con cargos mensuales más altos son más propensos a irse, la empresa podría considerar ofrecer descuentos o paquetes más asequibles a estos clientes. Si los clientes con contratos a corto plazo son más propensos a irse, la empresa podría considerar ofrecer incentivos para que estos clientes se cambien a contratos a largo plazo.\n",
      "\n",
      "3. **Sugerencias de Mejora**:\n",
      "\n",
      "Para mejorar el modelo, podríamos considerar varias estrategias. Primero, podríamos probar diferentes algoritmos de aprendizaje automático para ver si alguno de ellos ofrece una mejor precisión. Segundo, podríamos ajustar los parámetros del modelo RandomForest para optimizar su rendimiento. Tercero, podríamos considerar la posibilidad de recoger más datos o más características de los clientes que podrían ser relevantes para predecir el churn.\n",
      "\n",
      "Además, sería útil realizar un análisis de importancia de las características para identificar las variables más importantes para predecir el churn. Esto podría ayudarnos a entender mejor qué factores influyen en la decisión de un cliente de irse y a desarrollar estrategias más efectivas para retener a los clientes.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Quiero que realices un análisis exhaustivo de un modelo de ML que hemos desarrollado para realizar Churn y determianar si un cliente se va a ir. Aquí tienes los detalles relevantes del modelo y los datos:\n",
    "\n",
    "- Modelo utilizado: {modelo}.\n",
    "- Accuracy del modelo: {Accuracy}.\n",
    "- Las 10 variables más explicativas identificadas son: {Accuracy}.\n",
    "- Ejemplo del DataFrame utilizado (dos filas de muestra): {df_string}.\n",
    "\n",
    "Basado en esta información, por favor, realiza las siguientes tareas:\n",
    "1. **Análisis Técnico**: Evalúa la efectividad del modelo considerando su accuracy y las variables más explicativas. Ofrece una interpretación de por qué estas variables son importantes para el objetivo del modelo.\n",
    "2. **Análisis de Negocio**: Basado en el análisis técnico, proporciona un análisis de negocios sobre cómo este modelo puede ser aplicado para generar valor en [especificar el contexto del negocio, como aumentar las ventas, reducir costos, mejorar la satisfacción del cliente, etc.]. Incluye posibles estrategias y acciones recomendadas.\n",
    "3. **Sugerencias de Mejora**: Proporciona recomendaciones sobre cómo podemos mejorar el modelo o los datos para aumentar la precisión y la relevancia del negocio.\n",
    "\n",
    "Por favor, presenta tus hallazgos y recomendaciones en un formato estructurado que podamos utilizar para informar nuestras decisiones de negocio.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "response4 = get_completion(prompt)\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_tokens 330\n",
      "output_tokens 404\n",
      "costo en dolares:  0.03414 costo en pesos:  44.382\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = estimar_tokens(prompt)\n",
    "print(\"prompt_tokens\",prompt_tokens)\n",
    "output_tokens = estimar_tokens(response4)\n",
    "print(\"output_tokens\",output_tokens)\n",
    "\n",
    "costo = round(calcular_costo_gpt4(prompt_tokens,output_tokens),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el archivo se pudo leer con exito\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Card Type</th>\n",
       "      <th>Point Earned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  RowNumber  CustomerId   Surname  \\\n",
       "0             0             0           0          1    15634602  Hargrave   \n",
       "1             1             1           1          2    15647311      Hill   \n",
       "2             2             2           2          3    15619304      Onio   \n",
       "\n",
       "   CreditScore Geography  Gender  Age  ...    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42  ...       0.00              1   \n",
       "1          608     Spain  Female   41  ...   83807.86              1   \n",
       "2          502    France  Female   42  ...  159660.80              3   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  Complain  \\\n",
       "0          1               1        101348.88       1         1   \n",
       "1          0               1        112542.58       0         1   \n",
       "2          1               0        113931.57       1         1   \n",
       "\n",
       "   Satisfaction Score  Card Type Point Earned  \n",
       "0                   2    DIAMOND          464  \n",
       "1                   3    DIAMOND          456  \n",
       "2                   3    DIAMOND          377  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"Customer-Churn-Records.csv\"\n",
    "file_path = \"datos_input/Customer-Churn-Records.csv\"\n",
    "\n",
    "df2 = read_file(file_name,file_path)\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string = df2.head(2).to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"columnas_a_eliminar\": [\"Unnamed: 0.2\", \"Unnamed: 0.1\", \"Unnamed: 0\", \"RowNumber\", \"CustomerId\", \"Surname\"],\n",
      "  \"columnas_a_considerar\": [\"HasCrCard\", \"IsActiveMember\", \"Complain\", \"Card Type\"],\n",
      "  \"razones\": {\n",
      "    \"eliminar\": {\n",
      "      \"Unnamed: 0.2\": \"Esta columna parece ser un índice redundante.\",\n",
      "      \"Unnamed: 0.1\": \"Esta columna parece ser un índice redundante.\",\n",
      "      \"Unnamed: 0\": \"Esta columna parece ser un índice redundante.\",\n",
      "      \"RowNumber\": \"Esta columna parece ser un índice redundante.\",\n",
      "      \"CustomerId\": \"El ID del cliente no debería tener un impacto en la variable objetivo 'y'.\",\n",
      "      \"Surname\": \"El apellido del cliente no debería tener un impacto en la variable objetivo 'y'.\"\n",
      "    },\n",
      "    \"considerar\": {\n",
      "      \"HasCrCard\": \"Dependiendo del contexto, tener una tarjeta de crédito podría no ser relevante para la variable objetivo 'y'.\",\n",
      "      \"IsActiveMember\": \"Dependiendo del contexto, ser un miembro activo podría no ser relevante para la variable objetivo 'y'.\",\n",
      "      \"Complain\": \"Dependiendo del contexto, si un cliente se queja o no podría no ser relevante para la variable objetivo 'y'.\",\n",
      "      \"Card Type\": \"Dependiendo del contexto, el tipo de tarjeta podría no ser relevante para la variable objetivo 'y'.\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Dado el siguiente DataFrame con una muestra de dos filas y varias columnas,\n",
    "identifica qué columnas podrían ser innecesarias para un análisis en el que la columna 'y'\n",
    "es la variable objetivo.\n",
    "Considera factores como redundancia de datos, relevancia para la predicción de la variable objetivo,\n",
    "y cualquier otro criterio analítico que consideres pertinente. Retorna el resultado en un formato JSON,\n",
    "especificando las columnas a eliminar como una lista y las que tal vez deberia eliminar con otra lista y proporciona una breve explicación de por qué deberían ser eliminadas.\n",
    "Ejemplo de DataFrame: {df_string}\"\"\"\n",
    "\n",
    "response3 = get_completion(prompt)\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_tokens 170\n",
      "output_tokens 179\n",
      "costo en dolares:  0.01584 costo en pesos:  20.592\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = estimar_tokens(prompt)\n",
    "print(\"prompt_tokens\",prompt_tokens)\n",
    "output_tokens = estimar_tokens(response3)\n",
    "print(\"output_tokens\",output_tokens)\n",
    "\n",
    "costo = round(calcular_costo_gpt4(prompt_tokens,output_tokens),5)\n",
    "print(\"costo en dolares: \",costo,\"costo en pesos: \",costo*1300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
